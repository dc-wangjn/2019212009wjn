{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Indicate function\n",
    "def sign(x):\n",
    "    cx = np.copy(x)\n",
    "    length = cx.shape[0]\n",
    "    signal = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        if x[i,0] != 0:\n",
    "            signal[i] = x[i,0] / abs(x[i,0])\n",
    "        else:\n",
    "            signal[i] = 0;\n",
    "    return signal.reshape(length,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a value with each element in a vector\n",
    "# and replace the element with the max one\n",
    "def vec_max(value, vector):\n",
    "    for i in range(len(vector)):\n",
    "        vector[i] = max(value, vector[i,0])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f(x) = (1/2)||x'beta-y||^2\n",
    "# Gradient of f(x) = 2*x'(x'beta - y)\n",
    "def grf(A,x,y):\n",
    "    return A.T.dot(A.dot(x) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso_proximal(X,y,lamb,MAX_ITER=2000):\n",
    "    epsilon = 1e-4\n",
    "    n = X.shape[1]\n",
    "    beta = np.zeros(shape=(n,1))\n",
    "    miu = np.linspace(0.0001,0.0001,n).reshape(1,n)\n",
    "    cy = y.reshape(len(y),1)\n",
    "    y = cy\n",
    "    for i in range(MAX_ITER):\n",
    "        beta_kplus1 = beta - miu.T*grf(X,beta,y)\n",
    "        beta_kplus1 = vec_max(0, abs(beta_kplus1) - miu.T * lamb) * sign(beta_kplus1)\n",
    "        if sum(abs(beta_kplus1 - beta)) < epsilon:\n",
    "            beta = beta_kplus1\n",
    "            break\n",
    "        else:\n",
    "            beta = beta_kplus1\n",
    "#     print(i)\n",
    "#     print(sum(abs(beta_kplus1 - beta)))\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_X(X):\n",
    "    # Calculate mean  \n",
    "    X_mean = X.mean(axis=0)  \n",
    "    # Calculate variance   \n",
    "    X_std = X.std(axis=0)  \n",
    "    # Standardize X  \n",
    "    X1 = (X-X_mean)/X_std\n",
    "    return X1\n",
    "\n",
    "def normalization_y(y):\n",
    "    # Calculate mean  \n",
    "    y_mean = y.mean  \n",
    "    # Calculate variance   \n",
    "    y_std = y.std  \n",
    "    # Standardize y  \n",
    "    y1 = (y-y_mean)/y_std\n",
    "    return y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I use BIC as criterion\n",
    "# BIC = n * ln(mse) + k * ln(n)\n",
    "def get_BIC(y_pre,y_real,beta):\n",
    "    mse = mean_squared_error(y_real,y_pre)\n",
    "    n = len(y_real)\n",
    "    k = sum(abs(sign(beta)))\n",
    "    bic = n * math.log(mse) + k * np.log(n)\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get train and test data\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=19990226)\n",
    "\n",
    "# Before using lasso, standardize the data\n",
    "X_train_n = normalization_X(X_train)\n",
    "X_test_n = normalization_X(X_test)\n",
    "y_train_n = normalization_X(y_train)\n",
    "y_test_n = normalization_X(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, lambda = 0.001000, BIC = -35.274220\n",
      "1, lambda = 0.001259, BIC = -35.274252\n",
      "2, lambda = 0.001585, BIC = -35.274165\n",
      "3, lambda = 0.001995, BIC = -35.274110\n",
      "4, lambda = 0.002512, BIC = -35.274217\n",
      "5, lambda = 0.003162, BIC = -35.274295\n",
      "6, lambda = 0.003981, BIC = -35.274393\n",
      "7, lambda = 0.005012, BIC = -35.274381\n",
      "8, lambda = 0.006310, BIC = -35.274580\n",
      "9, lambda = 0.007943, BIC = -35.274668\n",
      "10, lambda = 0.010000, BIC = -35.274776\n",
      "11, lambda = 0.012589, BIC = -35.274985\n",
      "12, lambda = 0.015849, BIC = -35.275170\n",
      "13, lambda = 0.019953, BIC = -35.275488\n",
      "14, lambda = 0.025119, BIC = -35.275902\n",
      "15, lambda = 0.031623, BIC = -35.276223\n",
      "16, lambda = 0.039811, BIC = -35.276711\n",
      "17, lambda = 0.050119, BIC = -35.277250\n",
      "18, lambda = 0.063096, BIC = -35.277756\n",
      "19, lambda = 0.079433, BIC = -35.278478\n",
      "20, lambda = 0.100000, BIC = -35.278968\n",
      "21, lambda = 0.125893, BIC = -35.279346\n",
      "22, lambda = 0.158489, BIC = -35.279353\n",
      "23, lambda = 0.199526, BIC = -35.278555\n",
      "24, lambda = 0.251189, BIC = -35.276421\n",
      "25, lambda = 0.316228, BIC = -35.271607\n",
      "26, lambda = 0.398107, BIC = -35.262645\n",
      "27, lambda = 0.501187, BIC = -37.810903\n",
      "28, lambda = 0.630957, BIC = -38.675959\n",
      "29, lambda = 0.794328, BIC = -38.683261\n",
      "30, lambda = 1.000000, BIC = -39.527267\n",
      "31, lambda = 1.258925, BIC = -40.339015\n",
      "32, lambda = 1.584893, BIC = -41.101441\n",
      "33, lambda = 1.995262, BIC = -41.775856\n",
      "34, lambda = 2.511886, BIC = -41.466667\n",
      "35, lambda = 3.162278, BIC = -41.847070\n",
      "36, lambda = 3.981072, BIC = -43.886504\n",
      "37, lambda = 5.011872, BIC = -47.631547\n",
      "38, lambda = 6.309573, BIC = -50.679942\n",
      "39, lambda = 7.943282, BIC = -51.583768\n",
      "40, lambda = 10.000000, BIC = -50.110813\n",
      "41, lambda = 12.589254, BIC = -49.172768\n",
      "42, lambda = 15.848932, BIC = -48.426272\n",
      "43, lambda = 19.952623, BIC = -52.889276\n",
      "44, lambda = 25.118864, BIC = -54.790635\n",
      "45, lambda = 31.622777, BIC = -56.814959\n",
      "46, lambda = 39.810717, BIC = -58.190974\n",
      "47, lambda = 50.118723, BIC = -57.664535\n",
      "48, lambda = 63.095734, BIC = -54.484306\n",
      "49, lambda = 79.432823, BIC = -47.900108\n",
      "50, lambda = 100.000000, BIC = -39.794189\n",
      "51, lambda = 125.892541, BIC = -30.837765\n",
      "52, lambda = 158.489319, BIC = -16.881464\n",
      "53, lambda = 199.526231, BIC = -2.833587\n",
      "54, lambda = 251.188643, BIC = -2.105949\n",
      "55, lambda = 316.227766, BIC = -2.105949\n",
      "56, lambda = 398.107171, BIC = -2.105949\n",
      "57, lambda = 501.187234, BIC = -2.105949\n",
      "58, lambda = 630.957344, BIC = -2.105949\n",
      "59, lambda = 794.328235, BIC = -2.105949\n",
      "60, lambda = 1000.000000, BIC = -2.105949\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "num_folds = 5\n",
    "lambda_choices = [pow(10, -3+0.1*i) for i in range(61)]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "\n",
    "X_train_folds = np.array_split(X_train_n, num_folds)\n",
    "y_train_folds = np.array_split(y_train_n, num_folds)\n",
    "\n",
    "lambda_to_bic = {}\n",
    "\n",
    "for lamb in lambda_choices:\n",
    "    bic = []\n",
    "    for i in range(num_folds):\n",
    "        Xtr = np.concatenate(X_train_folds[:i] + X_train_folds[i+1:])\n",
    "        ytr = np.concatenate(y_train_folds[:i] + y_train_folds[i+1:])\n",
    "        Xcv = X_train_folds[i]\n",
    "        ycv = y_train_folds[i]\n",
    "        beta = lasso_proximal(Xtr,ytr,lamb,MAX_ITER=10000)\n",
    "        ycv_predict=Xcv.dot(beta)\n",
    "        bic_predict = get_BIC(ycv,ycv_predict,beta)\n",
    "        bic.append(bic_predict)\n",
    "    lambda_to_bic[lamb] = bic\n",
    "        \n",
    "i = 0  \n",
    "for lamb in sorted(lambda_to_bic):\n",
    "    bic = np.mean(lambda_to_bic[lamb])\n",
    "    print('%d, lambda = %f, BIC = %f' % (i, lamb, bic))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.2842712 ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.        ],\n",
       "       [-0.00433538],\n",
       "       [-0.15349921],\n",
       "       [ 0.02196104],\n",
       "       [-0.39434989]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# According to BIC, we know when lambda = 39.810717, the model works best\n",
    "beta = lasso_proximal(X_train_n,y_train_n,39.810717,MAX_ITER=10000)\n",
    "# Output parameter matrix\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-120.63166839]\n",
      "0.33584819990680576\n"
     ]
    }
   ],
   "source": [
    "y_test_predict=X_test_n.dot(beta)\n",
    "\n",
    "# Model evaluation (BIC and mse)\n",
    "bic_predict = get_BIC(y_test_n,y_test_predict,beta)\n",
    "mse_final = mean_squared_error(y_test_n,y_test_predict)\n",
    "print(bic_predict)\n",
    "\n",
    "# Although using BIC to choose model is good enough, MSE is still an important evaluation criteria\n",
    "print(mse_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0 CRIM 城市人均犯罪率\n",
      "0.0 ZN 占地面积超过 25,000 平方英尺的住宅用地比例\n",
      "-0.0 INDUS 每个城镇非零售业务的比例\n",
      "0.0 CHAS Charles River 虚拟变量（如果是河道，则为 1; 否则为 0）\n",
      "-0.0 NOX 一氧化氮浓度（每千万份）\n",
      "0.2843 RM 每间住宅的平均房间数\n",
      "-0.0 AGE 1940 年以前建造的自住单位比例\n",
      "-0.0 DIS 加权距离波士顿的五个就业中心\n",
      "-0.0 RAD 径向高速公路的可达性指数\n",
      "-0.0043 TAX 每 10000 美元的全值财产税率\n",
      "-0.1535 PTRATIO 城镇的学生与教师比例\n",
      "0.022 B B=1000(Bk −0.63)2 其中 Bk 是城镇黑人的比例\n",
      "-0.3943 LSTAT 人口中低收入者的比例\n"
     ]
    }
   ],
   "source": [
    "boston['feature_names_Chinese'] = np.array(['城市人均犯罪率',\n",
    "                                            '占地面积超过 25,000 平方英尺的住宅用地比例',\n",
    "                                            '每个城镇非零售业务的比例',\n",
    "                                            'Charles River 虚拟变量（如果是河道，则为 1; 否则为 0）',\n",
    "                                            '一氧化氮浓度（每千万份）',\n",
    "                                            '每间住宅的平均房间数',\n",
    "                                            '1940 年以前建造的自住单位比例',\n",
    "                                            '加权距离波士顿的五个就业中心',\n",
    "                                            '径向高速公路的可达性指数', \n",
    "                                            '每 10000 美元的全值财产税率',\n",
    "                                            '城镇的学生与教师比例',\n",
    "                                            'B=1000(Bk −0.63)2 其中 Bk 是城镇黑人的比例',\n",
    "                                            '人口中低收入者的比例'])\n",
    "for i in range(len(beta)):\n",
    "    print(round(beta[i,0],4), boston['feature_names'][i], boston['feature_names_Chinese'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据参数的估计结果可以得到，对于房价预测较为有效的变量有每间住宅的平均房间数，每 10000 美元的全值财产税率，城镇的学生与教师比例，B=1000(Bk −0.63)2 其中 Bk 是城镇黑人的比例（这一变量与黑人比例正相关）和人口中低收入者的比例。\n",
    "### 其中每间住宅的平均房间数，城镇的学生与教师比例，人口中低收入者的比例，这三个变量的系数绝对值较大，在房价预测的过程中较为重要。\n",
    "### 与房价正相关的是每间住宅的平均房间数和黑人比例。前者容易解释，房间越多通常意味着房子更大，而大房子理所当然卖的比较贵。城镇中的黑人比例与房价正相关则可能是商家不希望有大量黑人住进自己出售的小区中（这可能会让有购买力的白人选择其他商家的小区），因而通过提价的方式筛选消费者。但这一点并不显著，可以看到这一项的系数的绝对值非常小。\n",
    "### 每 10000 美元的全值财产税率，城镇的学生与教师比例，人口中低收入者的比例，这三个变量与房价负相关。这些都比较好理解，税率高的地方人们购买力低，学生的购买力低，所以学生比例高的地方群体的购买力也比较低，低收入者比例高的群体购买力也不高，而房价与人们的购买力正相关，因此与这三个变量负相关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: [0.68104429] realcat: 0.24780210802208244\n",
      "predict: [-0.66318347] realcat: -0.21707260770315176\n",
      "predict: [0.21246598] realcat: -0.23920949892816282\n",
      "predict: [-0.19508234] realcat: -0.11745659719060171\n",
      "predict: [0.24330481] realcat: 0.048570086996981954\n",
      "predict: [1.37715847] realcat: 2.350806774398142\n",
      "predict: [-2.0258569] realcat: -1.3571225057912264\n",
      "predict: [0.40040193] realcat: 0.41382879220966606\n",
      "predict: [0.21719516] realcat: 0.03750164138447661\n",
      "predict: [0.02462065] realcat: -0.19493571647814067\n",
      "predict: [-0.0828477] realcat: -0.46057841117827436\n",
      "predict: [-0.05034548] realcat: -0.25027794454066854\n",
      "predict: [-0.31784193] realcat: -0.2613463901531743\n",
      "predict: [0.45803775] realcat: 0.004296304546959799\n",
      "predict: [-0.69696995] realcat: -1.7223812110039105\n",
      "predict: [-0.83770832] realcat: -1.390327842628743\n",
      "predict: [-0.08670846] realcat: -0.1727988252531296\n",
      "predict: [-0.81435517] realcat: -0.8701108988409809\n",
      "predict: [-0.18699752] realcat: -0.34989395505321863\n",
      "predict: [1.21465222] realcat: 1.520673353460224\n",
      "predict: [-1.66657115] realcat: -1.5784914180413379\n",
      "predict: [-0.3116343] realcat: -0.15066193402811853\n",
      "predict: [-0.526616] realcat: -0.3720308462782301\n",
      "predict: [-0.47794915] realcat: -0.44950996556576905\n",
      "predict: [0.43984679] realcat: 0.38062345537214926\n",
      "predict: [-0.44703619] realcat: -0.8369055620034642\n",
      "predict: [-0.30219414] realcat: -0.0842512603530849\n",
      "predict: [0.12497468] realcat: -0.39416773750324113\n",
      "predict: [-0.48736624] realcat: -0.6819473234283859\n",
      "predict: [0.79555027] realcat: 0.6462661500722834\n",
      "predict: [-0.51555144] realcat: -1.04720602864107\n",
      "predict: [0.57623241] realcat: 0.1260492062845209\n",
      "predict: [1.0141863] realcat: 1.5760155815227517\n",
      "predict: [-0.89720061] realcat: -0.9807953549660366\n",
      "predict: [0.11236775] realcat: -0.21707260770315176\n",
      "predict: [0.61999037] realcat: 0.10391231505950985\n",
      "predict: [-0.73929203] realcat: -0.8811793444534864\n",
      "predict: [-1.31032506] realcat: -1.965887014479033\n",
      "predict: [0.8810552] realcat: 0.5245132483347219\n",
      "predict: [-0.78606425] realcat: -1.312848723341204\n",
      "predict: [-0.92196973] realcat: -0.9143846812910033\n",
      "predict: [0.89731388] realcat: 1.3989204517226623\n",
      "predict: [-0.22004169] realcat: -0.11745659719060171\n",
      "predict: [0.83674173] realcat: 0.9672510728349449\n",
      "predict: [-2.85316601] realcat: -0.9918638005785422\n",
      "predict: [-0.37152937] realcat: -0.9143846812910033\n",
      "predict: [0.47393377] realcat: -0.0842512603530849\n",
      "predict: [-0.26374807] realcat: -0.6266050953658581\n",
      "predict: [0.36936546] realcat: 0.14818609750953238\n",
      "predict: [-0.5385682] realcat: -1.1246851479286093\n",
      "predict: [-0.02008159] realcat: -0.7926317795534419\n",
      "predict: [0.40119181] realcat: 0.15925454312203774\n",
      "predict: [-0.14689353] realcat: -0.30562017260319646\n",
      "predict: [1.66657256] realcat: 2.8488868269608933\n",
      "predict: [0.27447249] realcat: -0.062114369128073825\n",
      "predict: [-0.23056157] realcat: -0.38309929189073544\n",
      "predict: [-0.64142796] realcat: -1.312848723341204\n",
      "predict: [-0.34407071] realcat: -0.5601944216908248\n",
      "predict: [-0.24018] realcat: -0.4716468567907801\n",
      "predict: [-0.8919048] realcat: -1.0693429198660813\n",
      "predict: [0.13888646] realcat: 3.014913511148477\n",
      "predict: [1.2907085] realcat: 1.465331125397696\n",
      "predict: [-0.29719336] realcat: -0.4384415199532633\n",
      "predict: [-1.14955986] realcat: -1.600628309266349\n",
      "predict: [-1.04163337] realcat: -0.604468204140847\n",
      "predict: [0.23667864] realcat: 0.07070697822199302\n",
      "predict: [0.16534761] realcat: -0.03997747790306275\n",
      "predict: [-0.61190853] realcat: -0.8701108988409809\n",
      "predict: [-0.02671927] realcat: 0.17032298873454346\n",
      "predict: [0.42740671] realcat: -0.07318281474057917\n",
      "predict: [0.67102976] realcat: 0.8787035079349003\n",
      "predict: [1.11605469] realcat: 0.9672510728349449\n",
      "predict: [0.23833333] realcat: -0.017840586678051277\n",
      "predict: [1.53814288] realcat: 2.1626431989855472\n",
      "predict: [-0.98781495] realcat: -0.09531970596559064\n",
      "predict: [1.29265929] realcat: 1.310372886822618\n",
      "predict: [0.67270326] realcat: 0.026433195771970876\n",
      "predict: [0.09560849] realcat: 0.19245987995955455\n",
      "predict: [-0.00040241] realcat: 3.014913511148477\n",
      "predict: [-0.54218169] realcat: -0.21707260770315176\n",
      "predict: [0.30252406] realcat: 0.004296304546959799\n",
      "predict: [0.0671251] realcat: 0.24780210802208244\n",
      "predict: [-0.25860593] realcat: 0.19245987995955455\n",
      "predict: [-1.01977855] realcat: -0.9697269093535311\n",
      "predict: [0.22180169] realcat: -0.25027794454066854\n",
      "predict: [-0.89225949] realcat: -0.9365215725160143\n",
      "predict: [0.03300198] realcat: 0.7569506061973391\n",
      "predict: [-0.87799169] realcat: -0.8369055620034642\n",
      "predict: [-0.88181597] realcat: -1.4567385163037765\n",
      "predict: [0.65860386] realcat: 0.48023946588469973\n",
      "predict: [0.48089294] realcat: -0.0842512603530849\n",
      "predict: [-1.08117409] realcat: -0.7926317795534419\n",
      "predict: [1.62702097] realcat: 2.4393543392981867\n",
      "predict: [0.29996672] realcat: 0.24780210802208244\n",
      "predict: [1.72607571] realcat: 2.0962325253105143\n",
      "predict: [1.47079472] realcat: 1.166483093860045\n",
      "predict: [0.00860482] realcat: -0.13959348841561278\n",
      "predict: [-1.52121767] realcat: -1.058274474253576\n",
      "predict: [0.87075909] realcat: 1.4763995710102018\n",
      "predict: [-0.6282792] realcat: -0.28348328137818535\n",
      "predict: [-0.37109845] realcat: -0.017840586678051277\n",
      "predict: [-0.32457763] realcat: -0.7372895514909138\n",
      "predict: [1.72834989] realcat: 3.014913511148477\n",
      "predict: [0.59069009] realcat: -0.0842512603530849\n",
      "predict: [0.14739565] realcat: -0.4052361831157465\n",
      "predict: [-0.36006776] realcat: -0.6155366497533526\n",
      "predict: [-0.02379162] realcat: -0.1727988252531296\n",
      "predict: [0.81819593] realcat: 0.7348137149723277\n",
      "predict: [0.4233905] realcat: -0.05104592351556809\n",
      "predict: [-1.5761303] realcat: 0.03750164138447661\n",
      "predict: [2.10865421] realcat: 3.014913511148477\n",
      "predict: [-0.55386812] realcat: -0.7372895514909138\n",
      "predict: [0.108809] realcat: 0.01536475015946514\n",
      "predict: [0.23243432] realcat: -0.3277570638282075\n",
      "predict: [-0.45001015] realcat: -0.34989395505321863\n",
      "predict: [-0.01220109] realcat: 0.03750164138447661\n",
      "predict: [-0.32288028] realcat: -0.526989084853308\n",
      "predict: [1.80269315] realcat: 3.014913511148477\n",
      "predict: [-0.41702947] realcat: -0.5933997585283416\n",
      "predict: [-0.70534536] realcat: -1.080411365478587\n",
      "predict: [-0.2618386] realcat: -0.27241483576567965\n",
      "predict: [-0.21955348] realcat: 0.03750164138447661\n",
      "predict: [0.13759312] realcat: -0.1727988252531296\n",
      "predict: [1.34610259] realcat: 2.649654805935793\n",
      "predict: [-0.23339895] realcat: -0.23920949892816282\n",
      "predict: [0.10505086] realcat: -0.3720308462782301\n",
      "predict: [-0.10679391] realcat: -0.41630462872825225\n",
      "predict: [0.59165996] realcat: 0.8122928342598671\n",
      "predict: [-0.14151395] realcat: -0.39416773750324113\n",
      "predict: [0.62024547] realcat: 0.059638532609487684\n",
      "predict: [-0.29945392] realcat: -0.2613463901531743\n",
      "predict: [-0.04970075] realcat: -0.38309929189073544\n",
      "predict: [0.36160321] realcat: -0.12852504280310706\n",
      "predict: [-0.06376016] realcat: -0.5933997585283416\n",
      "predict: [0.42520324] realcat: 0.2810074448595992\n",
      "predict: [0.23370103] realcat: -0.062114369128073825\n",
      "predict: [0.41429275] realcat: 0.22566521679707136\n",
      "predict: [1.12617968] realcat: 0.8122928342598671\n",
      "predict: [0.2821383] realcat: 0.01536475015946514\n",
      "predict: [-1.02298464] realcat: -0.33882550944071327\n",
      "predict: [0.15269637] realcat: -0.15066193402811853\n",
      "predict: [-0.49240946] realcat: -0.30562017260319646\n",
      "predict: [0.97970648] realcat: 0.9229772903849228\n",
      "predict: [-0.06871323] realcat: 0.026433195771970876\n",
      "predict: [-0.54973865] realcat: -0.549125976078319\n",
      "predict: [-0.61647004] realcat: -0.48271530240328586\n",
      "predict: [1.02927024] realcat: 1.0225933008974728\n",
      "predict: [0.05436576] realcat: 0.1813914343470488\n",
      "predict: [-0.92886704] realcat: -0.4052361831157465\n",
      "predict: [-0.44047631] realcat: -0.7040842146533974\n",
      "predict: [-0.78570286] realcat: -1.0693429198660813\n",
      "predict: [-0.45707657] realcat: -0.7483579971034195\n"
     ]
    }
   ],
   "source": [
    "# Show the differences between the prediction and the real data\n",
    "comparison = ['predict: '+str(a)+' realcat: '+str(b) for a,b in zip(y_test_predict,y_test_n)]\n",
    "for comp in comparison:\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面是使用sklearn中的lasso，用来与上面自己写的lasso进行效果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 0.6708499096392414 realcat: 0.24780210802208244\n",
      "predict: -0.5625818307603626 realcat: -0.21707260770315176\n",
      "predict: 0.11445727684021946 realcat: -0.23920949892816282\n",
      "predict: -0.5338705211839038 realcat: -0.11745659719060171\n",
      "predict: 0.15912254554955207 realcat: 0.048570086996981954\n",
      "predict: 1.2638185533120756 realcat: 2.350806774398142\n",
      "predict: -1.8678112851845607 realcat: -1.3571225057912264\n",
      "predict: 0.33588013212199413 realcat: 0.41382879220966606\n",
      "predict: 0.16903676016794558 realcat: 0.03750164138447661\n",
      "predict: -0.001266149528744344 realcat: -0.19493571647814067\n",
      "predict: 0.13266981330501093 realcat: -0.46057841117827436\n",
      "predict: 0.060879910103654934 realcat: -0.25027794454066854\n",
      "predict: -0.3588358925070914 realcat: -0.2613463901531743\n",
      "predict: 0.3573295726344921 realcat: 0.004296304546959799\n",
      "predict: -0.640831472202977 realcat: -1.7223812110039105\n",
      "predict: -0.7880749666048401 realcat: -1.390327842628743\n",
      "predict: -0.016033200957517323 realcat: -0.1727988252531296\n",
      "predict: -0.5307676252308403 realcat: -0.8701108988409809\n",
      "predict: -0.17770894274315813 realcat: -0.34989395505321863\n",
      "predict: 1.032931902377971 realcat: 1.520673353460224\n",
      "predict: -1.4700461043803612 realcat: -1.5784914180413379\n",
      "predict: -0.229292115278028 realcat: -0.15066193402811853\n",
      "predict: -0.5015418564719294 realcat: -0.3720308462782301\n",
      "predict: -0.37037217285013685 realcat: -0.44950996556576905\n",
      "predict: 0.5087516722781138 realcat: 0.38062345537214926\n",
      "predict: -0.3572824367388548 realcat: -0.8369055620034642\n",
      "predict: -0.35409016518230363 realcat: -0.0842512603530849\n",
      "predict: 0.05911607596597531 realcat: -0.39416773750324113\n",
      "predict: -0.4963486171656215 realcat: -0.6819473234283859\n",
      "predict: 0.7287213349854381 realcat: 0.6462661500722834\n",
      "predict: -0.5138496650483647 realcat: -1.04720602864107\n",
      "predict: 0.5623526510869029 realcat: 0.1260492062845209\n",
      "predict: 0.9626623061250583 realcat: 1.5760155815227517\n",
      "predict: -0.778105756569683 realcat: -0.9807953549660366\n",
      "predict: 0.04657310898170284 realcat: -0.21707260770315176\n",
      "predict: 0.6304472416373079 realcat: 0.10391231505950985\n",
      "predict: -0.6413165796136212 realcat: -0.8811793444534864\n",
      "predict: -1.095087897302756 realcat: -1.965887014479033\n",
      "predict: 0.5202903353021103 realcat: 0.5245132483347219\n",
      "predict: -0.4688807053275281 realcat: -1.312848723341204\n",
      "predict: -0.8744842949055767 realcat: -0.9143846812910033\n",
      "predict: 0.9327610769219723 realcat: 1.3989204517226623\n",
      "predict: -0.2593885929666632 realcat: -0.11745659719060171\n",
      "predict: 0.7372533487223409 realcat: 0.9672510728349449\n",
      "predict: -2.719242066357391 realcat: -0.9918638005785422\n",
      "predict: -0.3237635212878268 realcat: -0.9143846812910033\n",
      "predict: 0.41618533859869133 realcat: -0.0842512603530849\n",
      "predict: -0.27895248612707363 realcat: -0.6266050953658581\n",
      "predict: 0.5644050605279838 realcat: 0.14818609750953238\n",
      "predict: -0.4270889213951922 realcat: -1.1246851479286093\n",
      "predict: -0.05466606541475604 realcat: -0.7926317795534419\n",
      "predict: 0.36312171165898505 realcat: 0.15925454312203774\n",
      "predict: -0.1864795440858761 realcat: -0.30562017260319646\n",
      "predict: 1.470104337937916 realcat: 2.8488868269608933\n",
      "predict: 0.1821597214189788 realcat: -0.062114369128073825\n",
      "predict: -0.2805043199854523 realcat: -0.38309929189073544\n",
      "predict: -0.6068552330295739 realcat: -1.312848723341204\n",
      "predict: -0.2561487472882214 realcat: -0.5601944216908248\n",
      "predict: -0.16827105620607125 realcat: -0.4716468567907801\n",
      "predict: -0.8346615331633223 realcat: -1.0693429198660813\n",
      "predict: -0.05304075924841003 realcat: 3.014913511148477\n",
      "predict: 1.1043017514776816 realcat: 1.465331125397696\n",
      "predict: -0.3745571511729068 realcat: -0.4384415199532633\n",
      "predict: -1.0179451132281618 realcat: -1.600628309266349\n",
      "predict: -1.0939940039759255 realcat: -0.604468204140847\n",
      "predict: 0.2502380001060649 realcat: 0.07070697822199302\n",
      "predict: 0.12208839872389776 realcat: -0.03997747790306275\n",
      "predict: -0.43896914126031217 realcat: -0.8701108988409809\n",
      "predict: 0.08257972675326013 realcat: 0.17032298873454346\n",
      "predict: 0.34985471660969064 realcat: -0.07318281474057917\n",
      "predict: 0.5112958447880731 realcat: 0.8787035079349003\n",
      "predict: 1.0124444065485372 realcat: 0.9672510728349449\n",
      "predict: 0.12310913729438235 realcat: -0.017840586678051277\n",
      "predict: 1.4112998908346317 realcat: 2.1626431989855472\n",
      "predict: -0.8310417921000299 realcat: -0.09531970596559064\n",
      "predict: 1.1854720772963059 realcat: 1.310372886822618\n",
      "predict: 0.34417754383606847 realcat: 0.026433195771970876\n",
      "predict: 0.18784068511291918 realcat: 0.19245987995955455\n",
      "predict: 0.004169410861857324 realcat: 3.014913511148477\n",
      "predict: -0.38851094494113775 realcat: -0.21707260770315176\n",
      "predict: 0.19566496040158726 realcat: 0.004296304546959799\n",
      "predict: 0.19771832143247542 realcat: 0.24780210802208244\n",
      "predict: -0.2912728477396163 realcat: 0.19245987995955455\n",
      "predict: -1.0275860067686116 realcat: -0.9697269093535311\n",
      "predict: 0.23190509180866684 realcat: -0.25027794454066854\n",
      "predict: -0.8643282734442075 realcat: -0.9365215725160143\n",
      "predict: -0.06712845815524741 realcat: 0.7569506061973391\n",
      "predict: -0.8573162166010843 realcat: -0.8369055620034642\n",
      "predict: -0.590034193616764 realcat: -1.4567385163037765\n",
      "predict: 0.5997555498361631 realcat: 0.48023946588469973\n",
      "predict: 0.3629675805067331 realcat: -0.0842512603530849\n",
      "predict: -1.0149574115662334 realcat: -0.7926317795534419\n",
      "predict: 1.4268166894316503 realcat: 2.4393543392981867\n",
      "predict: 0.27871413780841636 realcat: 0.24780210802208244\n",
      "predict: 1.5665867060606524 realcat: 2.0962325253105143\n",
      "predict: 1.3599157914368367 realcat: 1.166483093860045\n",
      "predict: 0.05813546575550286 realcat: -0.13959348841561278\n",
      "predict: -1.3975478405205493 realcat: -1.058274474253576\n",
      "predict: 0.75247449822003 realcat: 1.4763995710102018\n",
      "predict: -0.5261252869826026 realcat: -0.28348328137818535\n",
      "predict: -0.23589140741741194 realcat: -0.017840586678051277\n",
      "predict: -0.18065789541566152 realcat: -0.7372895514909138\n",
      "predict: 1.5546669519706724 realcat: 3.014913511148477\n",
      "predict: 0.5533403621024005 realcat: -0.0842512603530849\n",
      "predict: 0.08387834199653355 realcat: -0.4052361831157465\n",
      "predict: -0.22604830143777857 realcat: -0.6155366497533526\n",
      "predict: -0.05162521567460567 realcat: -0.1727988252531296\n",
      "predict: 0.6915042747648916 realcat: 0.7348137149723277\n",
      "predict: 0.3404231526572289 realcat: -0.05104592351556809\n",
      "predict: -1.3181245838609525 realcat: 0.03750164138447661\n",
      "predict: 1.8526468243886696 realcat: 3.014913511148477\n",
      "predict: -0.4639559548762394 realcat: -0.7372895514909138\n",
      "predict: 0.1004085913986734 realcat: 0.01536475015946514\n",
      "predict: 0.24191688626971647 realcat: -0.3277570638282075\n",
      "predict: -0.4139297017294832 realcat: -0.34989395505321863\n",
      "predict: 0.048454572414325554 realcat: 0.03750164138447661\n",
      "predict: -0.3400374883742894 realcat: -0.526989084853308\n",
      "predict: 1.5842044773503032 realcat: 3.014913511148477\n",
      "predict: -0.37383565854446915 realcat: -0.5933997585283416\n",
      "predict: -0.5806424497822147 realcat: -1.080411365478587\n",
      "predict: -0.2703230043665875 realcat: -0.27241483576567965\n",
      "predict: -0.32710466423829637 realcat: 0.03750164138447661\n",
      "predict: 0.1272792301153661 realcat: -0.1727988252531296\n",
      "predict: 1.1971146595547435 realcat: 2.649654805935793\n",
      "predict: 0.040718158621205654 realcat: -0.23920949892816282\n",
      "predict: 0.08816098219169 realcat: -0.3720308462782301\n",
      "predict: -0.0760483435970028 realcat: -0.41630462872825225\n",
      "predict: 0.7957912981731432 realcat: 0.8122928342598671\n",
      "predict: -0.14594191858123706 realcat: -0.39416773750324113\n",
      "predict: 0.5791713043058264 realcat: 0.059638532609487684\n",
      "predict: -0.3617154803481319 realcat: -0.2613463901531743\n",
      "predict: -0.07407041033237016 realcat: -0.38309929189073544\n",
      "predict: 0.3101971434484347 realcat: -0.12852504280310706\n",
      "predict: -0.09846678427116398 realcat: -0.5933997585283416\n",
      "predict: 0.412586037721703 realcat: 0.2810074448595992\n",
      "predict: 0.32590110266780076 realcat: -0.062114369128073825\n",
      "predict: 0.4167424842191013 realcat: 0.22566521679707136\n",
      "predict: 0.9621669686767749 realcat: 0.8122928342598671\n",
      "predict: 0.411641431739084 realcat: 0.01536475015946514\n",
      "predict: -1.0110160722834494 realcat: -0.33882550944071327\n",
      "predict: 0.04092565036575175 realcat: -0.15066193402811853\n",
      "predict: -0.37991516663171554 realcat: -0.30562017260319646\n",
      "predict: 0.8882825837833659 realcat: 0.9229772903849228\n",
      "predict: -0.052359619588248925 realcat: 0.026433195771970876\n",
      "predict: -0.5518750358148674 realcat: -0.549125976078319\n",
      "predict: -0.5728521341344812 realcat: -0.48271530240328586\n",
      "predict: 0.9090119755487283 realcat: 1.0225933008974728\n",
      "predict: -0.21541030674301498 realcat: 0.1813914343470488\n",
      "predict: -0.8742410789786728 realcat: -0.4052361831157465\n",
      "predict: -0.29193857025996767 realcat: -0.7040842146533974\n",
      "predict: -0.5431391794453129 realcat: -1.0693429198660813\n",
      "predict: -0.36851931849367353 realcat: -0.7483579971034195\n",
      "Score:0.6301392647795254\n",
      "MSE:0.36986073522047463\n"
     ]
    }
   ],
   "source": [
    "# Use lasso which is in sklearn for comparison\n",
    "# According to MSE and the approximate value of parameters, \n",
    "# we can see that the program I wrote is similar to the one in sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lasso = linear_model.Lasso(alpha = 0.1)\n",
    "lasso.fit(X_train_n,y_train_n)\n",
    "y_predict = lasso.predict(X_test_n)\n",
    "comparison = ['predict: '+str(a)+' realcat: '+str(b) for a,b in zip(y_predict,y_test_n)]\n",
    "for comp in comparison:\n",
    "    print(comp)\n",
    "mse = mean_squared_error(y_test_n,lasso.predict(X_test_n))\n",
    "score = lasso.score(X_test_n,y_test_n)\n",
    "print('Score:{}'.format(score))\n",
    "print('MSE:{}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.        , -0.        ,  0.00956165, -0.        ,\n",
       "        0.28910624, -0.        , -0.        , -0.        , -0.00620989,\n",
       "       -0.15944122,  0.02927934, -0.39785725])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_\n",
    "# lasso.intercept_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
